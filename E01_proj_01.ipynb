{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a93f4b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## EX_01 proj.01 손글씨 분류하기 ##\n",
    "\n",
    "## 모듈 import\n",
    "# import sklearn\n",
    "# print(sklearn.__version__) #1.0\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import classification_report as cls_rpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6008bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "(1797,)\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7']\n",
      "      pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
      "0           0.0        0.0        5.0       13.0        9.0        1.0   \n",
      "1           0.0        0.0        0.0       12.0       13.0        5.0   \n",
      "2           0.0        0.0        0.0        4.0       15.0       12.0   \n",
      "3           0.0        0.0        7.0       15.0       13.0        1.0   \n",
      "4           0.0        0.0        0.0        1.0       11.0        0.0   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "1792        0.0        0.0        4.0       10.0       13.0        6.0   \n",
      "1793        0.0        0.0        6.0       16.0       13.0       11.0   \n",
      "1794        0.0        0.0        1.0       11.0       15.0        1.0   \n",
      "1795        0.0        0.0        2.0       10.0        7.0        0.0   \n",
      "1796        0.0        0.0       10.0       14.0        8.0        1.0   \n",
      "\n",
      "      pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_7  pixel_7_0  \\\n",
      "0           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "1           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "2           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "3           0.0        0.0        0.0        8.0  ...        0.0        0.0   \n",
      "4           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "...         ...        ...        ...        ...  ...        ...        ...   \n",
      "1792        0.0        0.0        0.0        1.0  ...        0.0        0.0   \n",
      "1793        1.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "1794        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "1795        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "1796        0.0        0.0        0.0        2.0  ...        0.0        0.0   \n",
      "\n",
      "      pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  pixel_7_6  \\\n",
      "0           0.0        6.0       13.0       10.0        0.0        0.0   \n",
      "1           0.0        0.0       11.0       16.0       10.0        0.0   \n",
      "2           0.0        0.0        3.0       11.0       16.0        9.0   \n",
      "3           0.0        7.0       13.0       13.0        9.0        0.0   \n",
      "4           0.0        0.0        2.0       16.0        4.0        0.0   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "1792        0.0        2.0       14.0       15.0        9.0        0.0   \n",
      "1793        0.0        6.0       16.0       14.0        6.0        0.0   \n",
      "1794        0.0        2.0        9.0       13.0        6.0        0.0   \n",
      "1795        0.0        5.0       12.0       16.0       12.0        0.0   \n",
      "1796        1.0        8.0       12.0       14.0       12.0        1.0   \n",
      "\n",
      "      pixel_7_7  target  \n",
      "0           0.0       0  \n",
      "1           0.0       1  \n",
      "2           0.0       2  \n",
      "3           0.0       3  \n",
      "4           0.0       4  \n",
      "...         ...     ...  \n",
      "1792        0.0       9  \n",
      "1793        0.0       0  \n",
      "1794        0.0       8  \n",
      "1795        0.0       9  \n",
      "1796        0.0       8  \n",
      "\n",
      "[1797 rows x 65 columns]\n",
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 1797\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 데이터 준비 & 살펴보기\n",
    "digit = load_digits(as_frame=True) #frame 확인: True\n",
    "digit_data = digit.data            #feature 데이터 지정\n",
    "digit_label = digit.target         #label 데이터 지정\n",
    "\n",
    "print(digit_data.shape)          #(1797, 64) / 64개 항목으로 이뤄진 1797개의 데이터\n",
    "print(digit_label.shape)         #(1797,)\n",
    "\n",
    "print(digit.target_names)        #target class 개수: [0 1 2 3 4 5 6 7 8 9] 총 10개\n",
    "print(digit.feature_names)       #feature columns가 그냥 pixel로 되어 있음\n",
    "print(digit.frame)               #frame 으로 구조 확인\n",
    "print(digit.DESCR)               #8x8 정수 이미지 픽셀 17개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9911a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1257, 64) (540, 64) (1257,) (540,)\n"
     ]
    }
   ],
   "source": [
    "## 데이터 분리\n",
    "x_train, x_test, y_train, y_test = tts(digit_data, digit_label, test_size=0.3, random_state=17)    #random_state 17 고정\n",
    "\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape) #(1257, 64), (540, 64), (1257,), (540,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16e2d78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95        51\n",
      "           1       0.78      0.78      0.78        59\n",
      "           2       0.82      0.82      0.82        49\n",
      "           3       0.86      0.75      0.80        57\n",
      "           4       0.80      0.88      0.84        56\n",
      "           5       0.83      0.92      0.87        59\n",
      "           6       0.93      0.91      0.92        47\n",
      "           7       0.93      0.91      0.92        56\n",
      "           8       0.79      0.79      0.79        48\n",
      "           9       0.86      0.84      0.85        58\n",
      "\n",
      "    accuracy                           0.85       540\n",
      "   macro avg       0.86      0.85      0.85       540\n",
      "weighted avg       0.86      0.85      0.85       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## decision tree test\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier as dtc\n",
    "\n",
    "model_tree = dtc(random_state=25)         \n",
    "model_tree.fit(x_train, y_train)\n",
    "tree_pred = model_tree.predict(x_test)\n",
    "\n",
    "print(cls_rpt(y_test, tree_pred))              #precision 0.85, recall 0.85, f1 score 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6504df26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        51\n",
      "           1       0.98      1.00      0.99        59\n",
      "           2       0.96      1.00      0.98        49\n",
      "           3       0.98      0.88      0.93        57\n",
      "           4       0.98      1.00      0.99        56\n",
      "           5       0.95      0.97      0.96        59\n",
      "           6       1.00      0.98      0.99        47\n",
      "           7       0.93      1.00      0.97        56\n",
      "           8       0.94      0.96      0.95        48\n",
      "           9       0.96      0.91      0.94        58\n",
      "\n",
      "    accuracy                           0.97       540\n",
      "   macro avg       0.97      0.97      0.97       540\n",
      "weighted avg       0.97      0.97      0.97       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## random forest test\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "\n",
    "model_randf = rfc(random_state=25)\n",
    "model_randf.fit(x_train, y_train)\n",
    "randf_pred = model_randf.predict(x_test)\n",
    "\n",
    "print(cls_rpt(y_test, randf_pred))             #precision 0.97, recall 0.97, f1 score 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9dfd8f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        51\n",
      "           1       0.89      0.93      0.91        59\n",
      "           2       0.94      1.00      0.97        49\n",
      "           3       0.96      0.84      0.90        57\n",
      "           4       1.00      0.95      0.97        56\n",
      "           5       0.90      0.95      0.93        59\n",
      "           6       0.98      0.98      0.98        47\n",
      "           7       0.96      0.98      0.97        56\n",
      "           8       0.86      0.92      0.89        48\n",
      "           9       0.89      0.84      0.87        58\n",
      "\n",
      "    accuracy                           0.94       540\n",
      "   macro avg       0.94      0.94      0.94       540\n",
      "weighted avg       0.94      0.94      0.93       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## SVM test\n",
    "\n",
    "from sklearn.svm import LinearSVC as l_svc\n",
    "\n",
    "model_svm = l_svc(random_state=25, C=5, max_iter = 100000)   # ConvergenceWarning 발생해서 iter 횟수 올려줌, 10만에서도 오류 발생\n",
    "\n",
    "model_svm = l_svc(random_state=25, max_iter = 1000000)    # C=5일때는 횟수 백만에서도 warning 뜸 -> 횟수 냅두고 C값 디폴트로\n",
    "\n",
    "model_svm.fit(x_train, y_train)\n",
    "svm_pred = model_svm.predict(x_test)\n",
    "\n",
    "print(cls_rpt(y_test, svm_pred))              # precision 0.94, recall 0.94, f1-score 0.93\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60e451f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        51\n",
      "           1       0.97      0.66      0.79        59\n",
      "           2       1.00      1.00      1.00        49\n",
      "           3       0.98      0.86      0.92        57\n",
      "           4       1.00      0.95      0.97        56\n",
      "           5       0.95      0.95      0.95        59\n",
      "           6       0.94      0.98      0.96        47\n",
      "           7       0.86      1.00      0.93        56\n",
      "           8       0.62      0.98      0.76        48\n",
      "           9       0.96      0.81      0.88        58\n",
      "\n",
      "    accuracy                           0.91       540\n",
      "   macro avg       0.93      0.92      0.91       540\n",
      "weighted avg       0.93      0.91      0.91       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## SGD test\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier as sgd\n",
    "\n",
    "model_sgd = sgd(random_state=25)\n",
    "model_sgd.fit(x_train, y_train)\n",
    "sgd_pred = model_sgd.predict(x_test)\n",
    "\n",
    "print(cls_rpt(y_test, sgd_pred))                # precision 0.93, recall 0.91, f1-score 0.91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16daff2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        51\n",
      "           1       0.96      0.93      0.95        59\n",
      "           2       0.98      1.00      0.99        49\n",
      "           3       0.98      0.93      0.95        57\n",
      "           4       1.00      0.98      0.99        56\n",
      "           5       0.97      0.95      0.96        59\n",
      "           6       0.98      0.98      0.98        47\n",
      "           7       0.98      1.00      0.99        56\n",
      "           8       0.88      0.96      0.92        48\n",
      "           9       0.95      0.97      0.96        58\n",
      "\n",
      "    accuracy                           0.97       540\n",
      "   macro avg       0.97      0.97      0.97       540\n",
      "weighted avg       0.97      0.97      0.97       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Logistics Regression test\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression as lgr\n",
    "\n",
    "# model_lgr = lgr(random_state=25)                  # iteration 오류 발생... 횟수를 늘려보자\n",
    "\n",
    "model_lgr = lgr(random_state=25, max_iter=100000)   # ok 해결\n",
    "model_lgr.fit(x_train, y_train)\n",
    "lgr_pred = model_lgr.predict(x_test)\n",
    "\n",
    "print(cls_rpt(y_test, lgr_pred))                  # precision 0.97, recall 0.97, f1-score 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec06a0ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 결과 모아서 보기\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score  # 다른거 확인하면서 적어놨으니까 여기선 acc만 임포트\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "ax1 = fig.add_subplot(2,2,1)       # precision\n",
    "ax2 = fig.add_subplot(2,2,2)       # recall\n",
    "ax3 = fig.add_subplot(2,2,3)       # f1 score\n",
    "ax4 = fig.add_subplot(2,2,4)       # accuracy\n",
    "\n",
    "acc1 = accuracy_score(y_test, tree_pred)\n",
    "acc2 = accuracy_score(y_test, randf_pred)\n",
    "acc3 = accuracy_score(y_test, svm_pred)\n",
    "acc4 = accuracy_score(y_test, sgd_pred)\n",
    "acc5 = accuracy_score(y_test, lgr_pred)\n",
    "\n",
    "subject = ['Tree', 'Rand_F', 'SVM', 'SGD', \"Logistic\"]\n",
    "\n",
    "points1 = [85, 97, 94, 93, 97]             # precision\n",
    "points2 = [85, 97, 94, 91, 97]             # recall\n",
    "points3 = [85, 97, 93, 91, 97]             # f1 score\n",
    "points4 = [acc1, acc2, acc3, acc4, acc5]   # accuracy\n",
    "\n",
    "ax1.bar(subject, points1)\n",
    "ax2.bar(subject, points2)\n",
    "ax3.bar(subject, points3)\n",
    "ax4.bar(subject, points4)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53944e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 결과\n",
    "\n",
    "# 손글씨 구분 문제는 원본을 얼마나 정확하게 판별하냐가 중요하므로\n",
    "# TP를 TP라고 맞춘 비율 = recall rate를 기준으로 판별\n",
    "\n",
    "# 결론: logistic, randomforest 분석이 적합\n",
    "\n",
    "\n",
    "## 후기(?)\n",
    "\n",
    "# 사실 4개 그래프 모두 위의 두 방법이 적합하다고 나오긴 하는데, 둘 중 뭐가 나을지는 아직 잘 모르겠다\n",
    "# SVM이 C값 잘 조절하면 두 방법보다 더 좋게 나올 수도 있을 거 같긴 한데 그 부분도 잘 모르겠다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
