{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb8b9d80",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## EX_01 proj.01 손글씨 분류하기 ##\n",
    "\n",
    "## 모듈 import\n",
    "# import sklearn\n",
    "# print(sklearn.__version__) #1.0\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import classification_report as cls_rpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8afd3677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "(1797,)\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7']\n",
      "      pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
      "0           0.0        0.0        5.0       13.0        9.0        1.0   \n",
      "1           0.0        0.0        0.0       12.0       13.0        5.0   \n",
      "2           0.0        0.0        0.0        4.0       15.0       12.0   \n",
      "3           0.0        0.0        7.0       15.0       13.0        1.0   \n",
      "4           0.0        0.0        0.0        1.0       11.0        0.0   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "1792        0.0        0.0        4.0       10.0       13.0        6.0   \n",
      "1793        0.0        0.0        6.0       16.0       13.0       11.0   \n",
      "1794        0.0        0.0        1.0       11.0       15.0        1.0   \n",
      "1795        0.0        0.0        2.0       10.0        7.0        0.0   \n",
      "1796        0.0        0.0       10.0       14.0        8.0        1.0   \n",
      "\n",
      "      pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_7  pixel_7_0  \\\n",
      "0           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "1           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "2           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "3           0.0        0.0        0.0        8.0  ...        0.0        0.0   \n",
      "4           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "...         ...        ...        ...        ...  ...        ...        ...   \n",
      "1792        0.0        0.0        0.0        1.0  ...        0.0        0.0   \n",
      "1793        1.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "1794        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "1795        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "1796        0.0        0.0        0.0        2.0  ...        0.0        0.0   \n",
      "\n",
      "      pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  pixel_7_6  \\\n",
      "0           0.0        6.0       13.0       10.0        0.0        0.0   \n",
      "1           0.0        0.0       11.0       16.0       10.0        0.0   \n",
      "2           0.0        0.0        3.0       11.0       16.0        9.0   \n",
      "3           0.0        7.0       13.0       13.0        9.0        0.0   \n",
      "4           0.0        0.0        2.0       16.0        4.0        0.0   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "1792        0.0        2.0       14.0       15.0        9.0        0.0   \n",
      "1793        0.0        6.0       16.0       14.0        6.0        0.0   \n",
      "1794        0.0        2.0        9.0       13.0        6.0        0.0   \n",
      "1795        0.0        5.0       12.0       16.0       12.0        0.0   \n",
      "1796        1.0        8.0       12.0       14.0       12.0        1.0   \n",
      "\n",
      "      pixel_7_7  target  \n",
      "0           0.0       0  \n",
      "1           0.0       1  \n",
      "2           0.0       2  \n",
      "3           0.0       3  \n",
      "4           0.0       4  \n",
      "...         ...     ...  \n",
      "1792        0.0       9  \n",
      "1793        0.0       0  \n",
      "1794        0.0       8  \n",
      "1795        0.0       9  \n",
      "1796        0.0       8  \n",
      "\n",
      "[1797 rows x 65 columns]\n",
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 1797\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 데이터 준비 & 살펴보기\n",
    "digit = load_digits(as_frame=True) #frame 확인: True\n",
    "digit_data = digit.data            #feature 데이터 지정\n",
    "digit_label = digit.target         #label 데이터 지정\n",
    "\n",
    "print(digit_data.shape)          #(1797, 64) / 64개 항목으로 이뤄진 1797개의 데이터\n",
    "print(digit_label.shape)         #(1797,)\n",
    "\n",
    "print(digit.target_names)        #target class 개수: [0 1 2 3 4 5 6 7 8 9] 총 10개\n",
    "print(digit.feature_names)       #feature columns가 그냥 pixel로 되어 있음\n",
    "print(digit.frame)               #frame 으로 구조 확인\n",
    "print(digit.DESCR)               #8x8 정수 이미지 픽셀 17개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d16c2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1257, 64) (540, 64) (1257,) (540,)\n"
     ]
    }
   ],
   "source": [
    "## 데이터 분리\n",
    "x_train, x_test, y_train, y_test = tts(digit_data, digit_label, test_size=0.3, random_state=17)    #random_state 17 고정\n",
    "\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape) #(1257, 64), (540, 64), (1257,), (540,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c49118cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95        51\n",
      "           1       0.78      0.78      0.78        59\n",
      "           2       0.82      0.82      0.82        49\n",
      "           3       0.86      0.75      0.80        57\n",
      "           4       0.80      0.88      0.84        56\n",
      "           5       0.83      0.92      0.87        59\n",
      "           6       0.93      0.91      0.92        47\n",
      "           7       0.93      0.91      0.92        56\n",
      "           8       0.79      0.79      0.79        48\n",
      "           9       0.86      0.84      0.85        58\n",
      "\n",
      "    accuracy                           0.85       540\n",
      "   macro avg       0.86      0.85      0.85       540\n",
      "weighted avg       0.86      0.85      0.85       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## decision tree test\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier as dtc\n",
    "\n",
    "model_tree = dtc(random_state=25)         \n",
    "model_tree.fit(x_train, y_train)\n",
    "tree_pred = model_tree.predict(x_test)\n",
    "\n",
    "print(cls_rpt(y_test, tree_pred))              #precision 0.86, recall 0.85, f1 score 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6766908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        51\n",
      "           1       0.98      1.00      0.99        59\n",
      "           2       0.96      1.00      0.98        49\n",
      "           3       0.98      0.88      0.93        57\n",
      "           4       0.98      1.00      0.99        56\n",
      "           5       0.95      0.97      0.96        59\n",
      "           6       1.00      0.98      0.99        47\n",
      "           7       0.93      1.00      0.97        56\n",
      "           8       0.94      0.96      0.95        48\n",
      "           9       0.96      0.91      0.94        58\n",
      "\n",
      "    accuracy                           0.97       540\n",
      "   macro avg       0.97      0.97      0.97       540\n",
      "weighted avg       0.97      0.97      0.97       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## random forest test\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "\n",
    "model_randf = rfc(random_state=25)\n",
    "model_randf.fit(x_train, y_train)\n",
    "randf_pred = model_randf.predict(x_test)\n",
    "\n",
    "print(cls_rpt(y_test, randf_pred))             #precision 0.97, recall 0.97, f1 score 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5649c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        51\n",
      "           1       0.89      0.93      0.91        59\n",
      "           2       0.94      1.00      0.97        49\n",
      "           3       0.96      0.84      0.90        57\n",
      "           4       1.00      0.95      0.97        56\n",
      "           5       0.90      0.95      0.93        59\n",
      "           6       0.98      0.98      0.98        47\n",
      "           7       0.96      0.98      0.97        56\n",
      "           8       0.86      0.92      0.89        48\n",
      "           9       0.89      0.84      0.87        58\n",
      "\n",
      "    accuracy                           0.94       540\n",
      "   macro avg       0.94      0.94      0.94       540\n",
      "weighted avg       0.94      0.94      0.93       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## SVM test\n",
    "\n",
    "from sklearn.svm import LinearSVC as l_svc\n",
    "\n",
    "# model_svm = l_svc(random_state=25, C=5, max_iter = 100000)   # ConvergenceWarning 발생해서 iter 횟수 올려줌, but 10만에서도 오류 발생\n",
    "\n",
    "model_svm = l_svc(random_state=25, max_iter = 1000000)    # C=5일때는 횟수 백만에서도 warning 뜸 -> 횟수 냅두고 C값 디폴트로\n",
    "\n",
    "model_svm.fit(x_train, y_train)\n",
    "svm_pred = model_svm.predict(x_test)\n",
    "\n",
    "print(cls_rpt(y_test, svm_pred))              # precision 0.94, recall 0.94, f1-score 0.93\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "221f90ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        51\n",
      "           1       0.97      0.66      0.79        59\n",
      "           2       1.00      1.00      1.00        49\n",
      "           3       0.98      0.86      0.92        57\n",
      "           4       1.00      0.95      0.97        56\n",
      "           5       0.95      0.95      0.95        59\n",
      "           6       0.94      0.98      0.96        47\n",
      "           7       0.86      1.00      0.93        56\n",
      "           8       0.62      0.98      0.76        48\n",
      "           9       0.96      0.81      0.88        58\n",
      "\n",
      "    accuracy                           0.91       540\n",
      "   macro avg       0.93      0.92      0.91       540\n",
      "weighted avg       0.93      0.91      0.91       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## SGD test\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier as sgd\n",
    "\n",
    "model_sgd = sgd(random_state=25)\n",
    "model_sgd.fit(x_train, y_train)\n",
    "sgd_pred = model_sgd.predict(x_test)\n",
    "\n",
    "print(cls_rpt(y_test, sgd_pred))                # precision 0.93, recall 0.91, f1-score 0.91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e9586ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        51\n",
      "           1       0.96      0.93      0.95        59\n",
      "           2       0.98      1.00      0.99        49\n",
      "           3       0.98      0.93      0.95        57\n",
      "           4       1.00      0.98      0.99        56\n",
      "           5       0.97      0.95      0.96        59\n",
      "           6       0.98      0.98      0.98        47\n",
      "           7       0.98      1.00      0.99        56\n",
      "           8       0.88      0.96      0.92        48\n",
      "           9       0.95      0.97      0.96        58\n",
      "\n",
      "    accuracy                           0.97       540\n",
      "   macro avg       0.97      0.97      0.97       540\n",
      "weighted avg       0.97      0.97      0.97       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Logistics Regression test\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression as lgr\n",
    "\n",
    "# model_lgr = lgr(random_state=25)                  # iteration 오류 발생... 횟수를 늘려보자\n",
    "\n",
    "model_lgr = lgr(random_state=25, max_iter=100000)   # ok 해결\n",
    "model_lgr.fit(x_train, y_train)\n",
    "lgr_pred = model_lgr.predict(x_test)\n",
    "\n",
    "print(cls_rpt(y_test, lgr_pred))                  # precision 0.97, recall 0.97, f1-score 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9964eade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 결과 모아서 보기\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score  # 다른거 확인하면서 적어놨으니까 여기선 acc만 임포트\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "ax1 = fig.add_subplot(2,2,1)       # precision\n",
    "ax2 = fig.add_subplot(2,2,2)       # recall\n",
    "ax3 = fig.add_subplot(2,2,3)       # f1 score\n",
    "ax4 = fig.add_subplot(2,2,4)       # accuracy\n",
    "\n",
    "acc1 = accuracy_score(y_test, tree_pred)\n",
    "acc2 = accuracy_score(y_test, randf_pred)\n",
    "acc3 = accuracy_score(y_test, svm_pred)\n",
    "acc4 = accuracy_score(y_test, sgd_pred)\n",
    "acc5 = accuracy_score(y_test, lgr_pred)\n",
    "\n",
    "subject = ['Tree', 'Rand_F', 'SVM', 'SGD', \"Logistic\"]\n",
    "\n",
    "points1 = [86, 97, 94, 93, 97]             # precision\n",
    "points2 = [85, 97, 94, 91, 97]             # recall\n",
    "points3 = [85, 97, 93, 91, 97]             # f1 score\n",
    "points4 = [acc1, acc2, acc3, acc4, acc5]   # accuracy\n",
    "\n",
    "ax1.bar(subject, points1)\n",
    "ax2.bar(subject, points2)\n",
    "ax3.bar(subject, points3)\n",
    "ax4.bar(subject, points4)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f588ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 결과\n",
    "\n",
    "# 손글씨 구분 문제는 원본을 얼마나 정확하게 판별하냐가 중요하므로\n",
    "# TP를 TP라고 맞춘 비율 = recall rate를 기준으로 판별\n",
    "\n",
    "# 결론: logistic, randomforest 분석이 적합\n",
    "\n",
    "\n",
    "## 후기(?)\n",
    "\n",
    "# 사실 4개 그래프 모두 위의 두 방법이 적합하다고 나오긴 하는데, 둘 중 뭐가 나을지는 아직 잘 모르겠다\n",
    "# SVM이 C값 잘 조절하면 두 방법보다 더 좋게 나올 수도 있을 거 같긴 한데 그 부분도 잘 모르겠다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
